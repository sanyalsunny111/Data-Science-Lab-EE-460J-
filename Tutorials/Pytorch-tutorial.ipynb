{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE460J Data Science Lab (Spring 2022)\n",
    "\n",
    "### Author: Sunny Sanyal\n",
    "This notebook reviews some of the basics of pytorch to be used in this course. This is just a warm before you jump right into the lab sessions. Following resources have been used in preparation of this tutorial:\n",
    "\n",
    "*  Python tutorial CS224N: Natural Language Processing with Deep Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation of cudatoolkit and creating environment\n",
    "\n",
    "1. Download cudatoolkit from __[here](https://developer.nvidia.com/cuda-downloads?target_os=Windows&target_arch=x86_64&target_version=11&target_type=exe_local)__ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating environment on anaconda prompt\n",
    "\n",
    "\n",
    "<code>conda create --name dl_env python=3.8.5\n",
    "conda activate dl_env\n",
    "conda install -c conda-forge tensorboardx tqdm python-louvain numpy pandas matplotlib \n",
    "conda install -c anaconda scikit-learn scipy pandas\n",
    "conda install pytorch torchvision cudatoolkit=11.3 -c pytorch\n",
    "</code>\n",
    "\n",
    "\n",
    "##### Adding the environment to your jupyter notebook\n",
    "\n",
    "\n",
    "<code>pip install --user ipykernel\n",
    "python -m ipykernel install --user --name=dl_env\n",
    "jupyter notebook \n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking if CUDA is available \n",
    "\n",
    "also if torch isn't running look __[here](https://stackoverflow.com/questions/69958526/oserror-winerror-127-the-specified-procedure-could-not-be-found)__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter()\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "\n",
    "Tensors are the most basic building blocks in PyTorch. Tensors are similar to matrices, but the have extra properties and they can represent higher dimensions. For example, an square image with 256 pixels in both sides can be represented by a 3x256x256 tensor, where the first 3 dimensions represent the color channels, red, green and blue.\n",
    "\n",
    "### Tensor Initialization\n",
    "\n",
    "There are several ways to instantiate tensors in PyTorch, which we will go through next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From a Python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "        [0,1],\n",
    "        [2,3],\n",
    "        [4,5]\n",
    "        ]\n",
    "nrow=len(data)\n",
    "ncol= len(data[0])\n",
    "print(nrow)\n",
    "print(ncol)\n",
    "#print(type(data))\n",
    "x_python = torch.tensor(data)\n",
    "\n",
    "# Print the tensor\n",
    "x_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 3.],\n",
       "        [4., 5.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We are using the dtype to create a tensor of particular type\n",
    "x_float = torch.tensor(data, dtype=torch.float)\n",
    "x_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We are using the dtype to create a tensor of particular type\n",
    "x_bool = torch.tensor(data, dtype=torch.bool)\n",
    "x_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 3.],\n",
       "        [4., 5.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_python.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 3.],\n",
       "        [4., 5.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `torch.Tensor` defaults to float\n",
    "# Same as torch.FloatTensor(data)\n",
    "x = torch.Tensor(data) \n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From a Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]], dtype=torch.int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize a tensor from a NumPy array\n",
    "ndarray = np.array(data)\n",
    "x_numpy = torch.from_numpy(ndarray)\n",
    "\n",
    "# Print the tensor\n",
    "x_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From a Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also initialize a tensor from another tensor, using the following methods:\n",
    "\n",
    "* torch.ones_like(old_tensor): Initializes a tensor of 1s.\n",
    "* torch.zeros_like(old_tensor): Initializes a tensor of 0s.\n",
    "* torch.rand_like(old_tensor): Initializes a tensor where all the elements are sampled from a uniform distribution between 0 and 1.\n",
    "* torch.randn_like(old_tensor): Initializes a tensor where all the elements are sampled from a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a base tensor\n",
    "x = torch.tensor([[1., 2.], [3., 4.]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a tensor of 0s\n",
    "x_zeros = torch.zeros_like(x)\n",
    "\n",
    "x_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a tensor of 1s\n",
    "x_ones = torch.ones_like(x)\n",
    "\n",
    "x_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5777, 0.4022],\n",
       "        [0.5218, 0.9841]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a tensor where each element is sampled from a uniform distribution\n",
    "# between 0 and 1\n",
    "\n",
    "x_rand = torch.rand_like(x)\n",
    "\n",
    "x_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3616,  1.1374],\n",
       "        [-0.6897,  2.2172]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a tensor where each element is sampled from a normal distribution\n",
    "x_randn = torch.randn_like(x)\n",
    "x_randn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Tensors specifying a Shape\n",
    "\n",
    "* torch.zeros()\n",
    "* torch.ones()\n",
    "* torch.rand()\n",
    "* torch.randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a 2x3x2 tensor\n",
    "\n",
    "shape = (4, 2, 2)\n",
    "x_zeros = torch.zeros(shape)\n",
    "\n",
    "x_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With torch.arange()\n",
    "\n",
    "We can also create a tensor with torch.arange(end), which returns a 1-D tensor with elements ranging from 0 to end-1. We can use the optional start and step parameters to create tensors with different ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor with values 1D\n",
    "\n",
    "x= torch.arange(10)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor Properties\n",
    "\n",
    "Tensors have a few properties that are important for us to cover. These are namely shape, and the device properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Data type\n",
    "The dtype property lets us see the data type of a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a 3x2 tensor, with 3 rows and 2 columns\n",
    "x = torch.Tensor([[1, 2], [3, 4], [5, 6]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out its shape\n",
    "# Same as x.size()\n",
    "x.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the number of elements in a particular dimension\n",
    "# 0th dimension corresponds to the rows\n",
    "x.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st dimension corresponds to the columns\n",
    "x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can change the shape of a tensor with the view( method\n",
    "# Example use of view()\n",
    "# x_view shares the same memory as x, so changing one changes the other\n",
    "x_view = x.view(3, 2)\n",
    "x_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_view1 = x.view(2, 3)\n",
    "x_view1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_view = x.view(-1, 3)\n",
    "x_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use torch.reshape() method for a similar purpose. There is a subtle difference between reshape() and view(): view() requires the data to be stored contiguously in the memory. You can refer to this StackOverflow answer for more information. In simple terms, contiguous means that the way our data is laid out in the memory is the same as the way we would read elements from it. This happens because some methods, such as transpose() and view(), do not actually change how our data is stored in the memory. They just change the meta information about out tensor, so that when we use it we will see the elements in the order we expect.\n",
    "\n",
    "reshape() calls view() internally if the data is stored contiguously, if not, it returns a copy. The difference here isn't too important for basic tensors, but if you perform operations that make the underlying storage of the data non-contiguous (such as taking a transpose), you will have issues using view(). If you would like to match the way your tensor is stored in the memory to how it is used, you can use the contiguous() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the shape of x to be 3x2\n",
    "# x_reshaped could be a reference to or copy of x\n",
    "x_reshaped = torch.reshape(x, (2, 3))\n",
    "x_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5],\n",
       "        [6, 7],\n",
       "        [8, 9]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a 5x2 tensor with 5 rows and 2 columns\n",
    "\n",
    "x =torch.arange(10).reshape(5,2)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5],\n",
       "        [6, 7],\n",
       "        [8, 9]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= torch.arange(10)\n",
    "x =torch.reshape(y, (5,2))\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 1, 1, 1, 1, 2])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new dimension of size 1 at the 1st dimension\n",
    "x = x.unsqueeze(1)\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5],\n",
       "        [6, 7],\n",
       "        [8, 9]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Squeeze the dimensions of x by getting rid of all the dimensions with 1 element\n",
    "x = x.squeeze()\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Squeeze the dimensions of x by getting rid of all the dimensions with 1 element\n",
    "x = x.squeeze()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of elements in tensor.\n",
    "x.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device\n",
    "\n",
    "Device property tells PyTorch where to store our tensor. Where a tensor is stored determines which device, GPU or CPU, would be handling the computations involving it. We can find the device of a tensor with the device property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an example tensor\n",
    "x = torch.Tensor([[1, 2], [3, 4]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the device of the tensor\n",
    "x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can move a tensor from one device to another with the method to(device).\n",
    "\n",
    "# Check if a GPU is available, if so, move the tensor to the GPU\n",
    "if torch.cuda.is_available():\n",
    "  x.to('cuda') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Indexing\n",
    "\n",
    "In PyTorch we can index tensors, similar to NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.],\n",
       "         [ 3.,  4.]],\n",
       "\n",
       "        [[ 5.,  6.],\n",
       "         [ 7.,  8.]],\n",
       "\n",
       "        [[ 9., 10.],\n",
       "         [11., 12.]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([\n",
    "                  [[1, 2], [3, 4]],\n",
    "                  [[5, 6], [7, 8]], \n",
    "                  [[9, 10], [11, 12]] \n",
    "                 ])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the 0th element, which is the first row\n",
    "x[0] # Equivalent to x[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2.],\n",
       "         [3., 4.]],\n",
       "\n",
       "        [[5., 6.],\n",
       "         [7., 8.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also access arbitrary elements in each dimension.\n",
    "\n",
    "# let's access the 0th and 1st elements\n",
    "i = torch.tensor([0,1])\n",
    "x[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 5., 9.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the top left element of each element in our tensor\n",
    "x[:, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0,0].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor Operations\n",
    "\n",
    "PyTorch operations are very similar to those of NumPy. We can work with both scalars and other tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x =  torch.ones((3,2,2))\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3., 3.],\n",
       "         [3., 3.]],\n",
       "\n",
       "        [[3., 3.],\n",
       "         [3., 3.]],\n",
       "\n",
       "        [[3., 3.],\n",
       "         [3., 3.]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform elementwise addition\n",
    "# Use - for subtraction\n",
    "x + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2., 2.],\n",
       "         [2., 2.]],\n",
       "\n",
       "        [[2., 2.],\n",
       "         [2., 2.]],\n",
       "\n",
       "        [[2., 2.],\n",
       "         [2., 2.]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform elementwise multiplication\n",
    "# Use / for division\n",
    "x * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6., 6., 6.],\n",
       "        [6., 6., 6.],\n",
       "        [6., 6., 6.],\n",
       "        [6., 6., 6.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones((4,3))\n",
    "\n",
    "a * 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 1D tensor of 2s\n",
    "b = torch.ones(3) * 2\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.5000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.5000]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divide a by b\n",
    "a / b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.5000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.5000]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6., 6., 6., 6.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use tensor.matmul(other_tensor) for matrix multiplication and tensor.T for transpose. Matrix multiplication can also be performed with @.\n",
    "# Alternative to a.matmul(b)\n",
    "# a @ b.T returns the same result since b is 1D tensor and the 2nd dimension\n",
    "# is inferred\n",
    "a @ b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(a.shape)\n",
    "pp.pprint(a.T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take the mean and standard deviation along a certain dimension with the methods mean(dim) and std(dim). That is, if we want to get the mean 3x2 matrix in a 4x3x2 matrix, we would set the dim to be 0. We can call these methods with no parameter to get the mean and standard deviation for the whole tensor. To use mean and std our tensor should be a floating point type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Mean: 2.5'\n",
      "'Mean in the 0th dimension: tensor([2.5000, 2.5000])'\n",
      "'Mean in the 1st dimension: tensor([1., 2., 3., 4.])'\n"
     ]
    }
   ],
   "source": [
    "m = torch.tensor(\n",
    "    [\n",
    "     [1., 1.],\n",
    "     [2., 2.],\n",
    "     [3., 3.],\n",
    "     [4., 4.]\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "pp.pprint('Mean: {}'.format(m.mean()))\n",
    "pp.pprint(\"Mean in the 0th dimension: {}\".format(m.mean(0)))\n",
    "pp.pprint(\"Mean in the 1st dimension: {}\".format(m.mean(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: torch.Size([4, 3])\n",
      "Initial shape: torch.Size([8, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can concatenate tensors using torch.cat.\n",
    "# concatenate in deomension 0 rows\n",
    "a_cat0 = torch.cat([a, a], dim=0)\n",
    "print(\"Initial shape: {}\".format(a.shape))\n",
    "print(\"Initial shape: {}\".format(a_cat0.shape))\n",
    "a_cat0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: torch.Size([4, 3])\n",
      "Initial shape: torch.Size([4, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate in deomension 1 columns\n",
    "a_cat1 = torch.cat([a, a], dim=1)\n",
    "print(\"Initial shape: {}\".format(a.shape))\n",
    "print(\"Initial shape: {}\".format(a_cat1.shape))\n",
    "a_cat1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograd\n",
    "\n",
    "PyTorch and other machine learning libraries are known for their automatic differantiation feature. That is, given that we have defined the set of operations that need to be performed, the framework itself can figure out how to compute the gradients. We can call the backward() method to ask PyTorch to calculate the gradiends, which are then stored in the grad attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create an example tensor\n",
    "# requires_grad parameter tells PyTorch to store gradients\n",
    "x = torch.tensor([2.], requires_grad=True)\n",
    "# no grad since it's a scalar\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([12.])\n"
     ]
    }
   ],
   "source": [
    "# Calculating the gradient of y with respect to x\n",
    "y = x * x * 3 #3x^2\n",
    "y.backward()\n",
    "print(x.grad) # d(y)/d(x) = d(3x^2)/d(x) = 6x = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.)\n",
      "tensor(4.)\n",
      "tensor(10.)\n"
     ]
    }
   ],
   "source": [
    "# Example 2 of Autograd with multiple variable\n",
    "\n",
    "a = torch.tensor(0.1, requires_grad = True)\n",
    "b = torch.tensor(1.0, requires_grad = True)\n",
    "c = torch.tensor(0.1, requires_grad = True)\n",
    "y=3*a + 2*b*b + torch.log(c)\n",
    "\n",
    "y.backward()\n",
    "\n",
    "print(a.grad) # tensor(3.)\n",
    "print(b.grad) # tensor(4.)\n",
    "print(c.grad) # tensor(10.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks\n",
    "\n",
    "So far we have looked into the tensors, their properties and basic operations on tensors. These are especially useful to get familiar with if we are building the layers of our network from scratch. We will utilize these in Assignment 3, but moving forward, we will use predefined blocks in the torch.nn module of PyTorch. We will then put together these blocks to create complex networks. Let's start by importing this module with an alias so that we don't have to type torch every time we use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Layer\n",
    "\n",
    "We can use nn.Linear(H_in, H_out) to create a a linear layer. This will take a matrix of (N, *, H_in) dimensions and output a matrix of (N, *, H_out). The * denotes that there could be arbitrary number of dimensions in between. The linear layer performs the operation Ax+b, where A and b are initialized randomly. If we don't want the linear layer to learn the bias parameters, we can initialize our layer with bias=False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6864, -0.1650],\n",
       "         [-0.6864, -0.1650],\n",
       "         [-0.6864, -0.1650]],\n",
       "\n",
       "        [[-0.6864, -0.1650],\n",
       "         [-0.6864, -0.1650],\n",
       "         [-0.6864, -0.1650]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the inputs \n",
    "input= torch.ones(2,3,4)\n",
    "\n",
    "print(input)\n",
    "\n",
    "# Make a linear layers transforming N,*,H_in dimensinal inputs to N,*,H_out\n",
    "# dimensional outputs\n",
    "linear = nn.Linear(4,2)\n",
    "linear_output = linear(input)\n",
    "linear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation Functions\n",
    "We can also use the nn module to apply activations functions to our tensors. Activation functions are used to add non-linearity to our network. Some examples of activations functions are nn.ReLU(), nn.Sigmoid() and nn.LeakyReLU(). Activation functions operate on each element seperately, so the shape of the tensors we get as an output are the same as the ones we pass in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6864, -0.1650],\n",
       "         [-0.6864, -0.1650],\n",
       "         [-0.6864, -0.1650]],\n",
       "\n",
       "        [[-0.6864, -0.1650],\n",
       "         [-0.6864, -0.1650],\n",
       "         [-0.6864, -0.1650]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3348, 0.4589],\n",
       "         [0.3348, 0.4589],\n",
       "         [0.3348, 0.4589]],\n",
       "\n",
       "        [[0.3348, 0.4589],\n",
       "         [0.3348, 0.4589],\n",
       "         [0.3348, 0.4589]]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid = nn.Sigmoid()\n",
    "output = sigmoid(linear_output)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting Layers together\n",
    "\n",
    "So far we have seen that we can create layers and pass the output of one as the input of the next. Instead of creating intermediate tensors and passing them around, we can use nn.Sequentual, which does exactly that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4466, 0.4141],\n",
       "         [0.4466, 0.4141],\n",
       "         [0.4466, 0.4141]],\n",
       "\n",
       "        [[0.4466, 0.4141],\n",
       "         [0.4466, 0.4141],\n",
       "         [0.4466, 0.4141]]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block = nn.Sequential(\n",
    "    nn.Linear(4, 2),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "input = torch.ones(2,3,4)\n",
    "output = block(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Modules\n",
    "Instead of using the predefined modules, we can also build our own by extending the nn.Module class. For example, we can build a the nn.Linear (which also extends nn.Module) on our own using the tensor introduced earlier! We can also build new, more complex modules, such as a custom neural network. \n",
    "\n",
    "To create a custom module, the first thing we have to do is to extend the nn.Module. We can then initialize our parameters in the __init__ function, starting with a call to the __init__ function of the super class. All the class attributes we define which are nn module objects are treated as parameters, which can be learned during the training. Tensors are not parameters, but they can be turned into parameters if they are wrapped in nn.Parameter class.\n",
    "\n",
    "All classes extending nn.Module are also expected to implement a forward(x) function, where x is a tensor. This is the function that is called when a parameter is passed to our module, such as in model(x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        #Call the _init_ function of the super class nn.Module\n",
    "        #this is called inheritence\n",
    "        super(MultilayerPerceptron, self).__init__()\n",
    "        \n",
    "        #saving the initial parameters\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        #defining our model\n",
    "        # There isn't anything specific about the naming of `self.model`. It could\n",
    "    # be something arbitrary.\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(self.input_size, self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_size, self.input_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6246, 0.5524, 0.5314, 0.4767, 0.5616],\n",
       "        [0.5474, 0.5172, 0.5384, 0.5579, 0.5687]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a sample input\n",
    "input =torch.randn(2,5)\n",
    "\n",
    "#Create model\n",
    "\n",
    "model = MultilayerPerceptron(5,3)\n",
    "\n",
    "#Pass the input through our model\n",
    "model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('model.0.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.3185,  0.4021, -0.3229, -0.1167,  0.1969],\n",
       "          [-0.1114, -0.1121,  0.1813,  0.1332,  0.4466],\n",
       "          [ 0.1096, -0.4241, -0.3529,  0.1510, -0.1970]], requires_grad=True)),\n",
       " ('model.0.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.3822,  0.3071, -0.0531], requires_grad=True)),\n",
       " ('model.2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1359,  0.2657, -0.2584],\n",
       "          [-0.4570,  0.4134,  0.4487],\n",
       "          [ 0.2326, -0.1005, -0.1244],\n",
       "          [ 0.2399, -0.2688,  0.2695],\n",
       "          [-0.2951,  0.1413,  0.3387]], requires_grad=True)),\n",
       " ('model.2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.2798, -0.1463,  0.2126,  0.1385,  0.1257], requires_grad=True))]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect parameters if the model\n",
    "list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer\n",
    "\n",
    "We have showed how gradients are calculated with the backward() function. Having the gradients isn't enought for our models to learn. We also need to know how to update the parameters of our models. This is where the optimizers comes in. torch.optim module contains several optimizers that we can use. Some popular examples are optim.SGD and optim.Adam. When initializing optimizers, we pass our model parameters, which can be accessed with model.parameters(), telling the optimizers which values it will be optimizing. Optimizers also has a learning rate (lr) parameter, which determines how big of an update will be made in every step. Different optimizers have different hyperparameters as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have our optimization function, we can define a loss that we want to optimize for. We can either define the loss ourselves, or use one of the predefined loss function in PyTorch, such as nn.BCELoss(). Let's put everything together now! We will start by creating some dummy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1410,  1.3278,  2.2789, -0.0587,  1.3465],\n",
       "        [ 1.8383,  0.9794,  1.6132,  0.6001,  1.4271],\n",
       "        [-0.0836,  2.0081,  1.5900,  1.3299,  3.1222],\n",
       "        [ 0.2449,  3.3850,  0.6343,  1.6930,  1.1947],\n",
       "        [ 2.7479, -0.1616,  2.4396,  0.4190,  1.0997],\n",
       "        [ 0.6747,  0.8883,  0.2801,  2.0999,  0.9491],\n",
       "        [-1.8206,  2.4538,  1.4040,  1.3073,  1.4065],\n",
       "        [-0.4987,  1.3135,  1.9775,  1.8416,  2.3042],\n",
       "        [-0.6039,  0.8761,  1.5620,  0.5114,  0.9238],\n",
       "        [-0.1877,  1.2864,  2.6097,  1.3650,  1.2611]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dummy data y\n",
    "y = torch.ones(10,5)\n",
    "\n",
    "#add some random noise\n",
    "x = y + torch.randn_like(y)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1675994396209717"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating the model\n",
    "\n",
    "model = MultilayerPerceptron(5, 3)\n",
    "\n",
    "# Define the optimizer\n",
    "adam = optim.Adam(model.parameters(), lr=1e-1)\n",
    "\n",
    "#Define Loss using a predefined loss function\n",
    "loss_function = nn.BCELoss()\n",
    "\n",
    "# compute the model performance\n",
    "y_pred = model(x)\n",
    "loss_function(y_pred, y).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: training loss: 1.1675994396209717\n",
      "Epoch 1: training loss: 0.8803694248199463\n",
      "Epoch 2: training loss: 0.6795225739479065\n",
      "Epoch 3: training loss: 0.5129404664039612\n",
      "Epoch 4: training loss: 0.36155399680137634\n",
      "Epoch 5: training loss: 0.23067373037338257\n",
      "Epoch 6: training loss: 0.1320425570011139\n",
      "Epoch 7: training loss: 0.06835171580314636\n",
      "Epoch 8: training loss: 0.032941725105047226\n",
      "Epoch 9: training loss: 0.015373587608337402\n"
     ]
    }
   ],
   "source": [
    "# set the number of iterations also called epochs\n",
    "n_epoch = 10\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    #set the gradients to zero\n",
    "    adam.zero_grad()\n",
    "    \n",
    "    #Get the model predictions\n",
    "    y_pred = model(x)\n",
    "    \n",
    "    # get the loss\n",
    "    loss = loss_function(y_pred, y)\n",
    "    \n",
    "    #Print stats\n",
    "    print(f\"Epoch {epoch}: training loss: {loss}\")\n",
    "    \n",
    "    #Compute the gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    #take a step to optimize the weights\n",
    "    adam.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that our loss is decreasing. Let's check the predictions of our model now and see if they are close to our original y, which was all 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9861, 0.9996, 0.9970, 0.9998, 0.9943],\n",
       "        [0.9899, 0.9998, 0.9981, 0.9999, 0.9962],\n",
       "        [0.9945, 0.9999, 0.9992, 1.0000, 0.9982],\n",
       "        [0.9908, 0.9998, 0.9983, 0.9999, 0.9966],\n",
       "        [0.9918, 0.9999, 0.9986, 0.9999, 0.9971],\n",
       "        [0.9764, 0.9989, 0.9939, 0.9995, 0.9890],\n",
       "        [0.9648, 0.9977, 0.9893, 0.9987, 0.9818],\n",
       "        [0.9910, 0.9998, 0.9984, 0.9999, 0.9967],\n",
       "        [0.9374, 0.9928, 0.9761, 0.9955, 0.9623],\n",
       "        [0.9877, 0.9997, 0.9975, 0.9999, 0.9952]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See how our model performs on the training data\n",
    "y_pred = model(x)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9808, 0.9993, 0.9954, 0.9996, 0.9915],\n",
       "        [0.9870, 0.9997, 0.9973, 0.9998, 0.9948],\n",
       "        [0.9781, 0.9991, 0.9945, 0.9995, 0.9900],\n",
       "        [0.9638, 0.9975, 0.9889, 0.9986, 0.9812],\n",
       "        [0.9605, 0.9971, 0.9875, 0.9984, 0.9790],\n",
       "        [0.9438, 0.9942, 0.9795, 0.9965, 0.9672],\n",
       "        [0.9876, 0.9997, 0.9975, 0.9999, 0.9951],\n",
       "        [0.9967, 1.0000, 0.9996, 1.0000, 0.9990],\n",
       "        [0.9830, 0.9994, 0.9961, 0.9997, 0.9927],\n",
       "        [0.9504, 0.9954, 0.9828, 0.9973, 0.9720]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create test data and check the model performance\n",
    "\n",
    "x2 = y + torch.randn_like(y)\n",
    "y_pred = model(x2)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Congratulations you have finished this tutora"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "dl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
